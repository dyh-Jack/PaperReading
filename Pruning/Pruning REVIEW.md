## Pruning Review

随着神经网络的不断发展，在其网络架构中存在大量的冗余参数（大部分权重在训练结束后数值趋近于0）。而将这些冗余参数去除，从而简化模型结构，减少参数数量，对于神经网络的部署具有重要意义。

最早期的dropout便是一种简单的剪枝技术。通过将一部分结构置0，从而完成在训练过程中的剪枝处理。

而如今，模型剪枝主要分为细粒度剪枝（连接剪枝）和粗粒度剪枝（通道剪枝）。

### GSM-SGD

文章主要思路为：

- 利用Momentum的SGD，使得大部分参数在梯度更新的过程中都趋向于0，并且由于动量的累计，得以加速这一过程，从而显著加快归零的过程。
- 在部分参数归零后，对这些参数进行剪枝，这可以保证在减少参数的同时不会对模型精度带来太大的影响。
- 而主动更新的部分则利用计算得到的梯度进行更新，来保持模型的精度

在此之前对于模型参数的剪枝存在两个问题：

1. 无法从根本上将集合$\theta$中的某一参数归零，这样在删去这个参数时，将不可避免的带来性能的损失（易得SGD无法将某一参数归零）
2. 超参数$\lambda$无法直接反应最终模型的压缩比，因此如需获得特定压缩比的模型，可能需要在之前进行多次实验从而获得一定的先验知识

![image-20220122154459585](C:\Users\dyh20200207\AppData\Roaming\Typora\typora-user-images\image-20220122154459585.png)

### AOFP

AOFP是一种通道剪枝算法，Channel Pruning的常见范式是根据某种方式评估卷积核的重要性，并将不太重要的卷积核去除

- Oracle Pruning（贪心算法）

对于特定的一层，先去除一个卷积核，然后在评估数据集上测试模型，记录准确率的平均下降数值，之后再恢复当前卷积核，并对下一卷积核进行相同操作，直到完成所有卷积核的测试，并按顺序删除对准确率影响最小的一些卷积核。

这种方法的问题在于，时间复杂度过高，且每次删除一组卷积核之后，由于其他卷积核此时的重要性会发生变化，因此都需要重新开始测试。

由于这样的时间复杂度过高，因此产生了根据删除卷积核所在层的下一层的输出来近似判断卷积核重要性的思路

![image-20220118215614338](C:\Users\dyh20200207\AppData\Roaming\Typora\typora-user-images\image-20220118215614338.png)

![image-20220122155258129](C:\Users\dyh20200207\AppData\Roaming\Typora\typora-user-images\image-20220122155258129.png)

![image-20220118220915823](C:\Users\dyh20200207\AppData\Roaming\Typora\typora-user-images\image-20220118220915823.png)

在此我们引入剪枝阈值$\theta$，我们说集合B足够好，当其满足：

![image-20220118221842063](C:\Users\dyh20200207\AppData\Roaming\Typora\typora-user-images\image-20220118221842063.png)

与此同时，g的值也得以确定，我们只需将g设定为每次搜索空间的二分之一即可。

### Centripetal SGD

![image-20220122160106227](C:\Users\dyh20200207\AppData\Roaming\Typora\typora-user-images\image-20220122160106227.png)

文章思路：

- 将每一层的卷积核分为不同的组，通过特殊的参数更新规则，使得每组卷积核的参数间的距离不断缩小，最后每个卷积核都逐渐成为本组的一个中心值
- 此时，只需在每组中取出一个卷积核即可，从而完成了剪枝，输出通道数相应的变为分组数量；此外，由于输出特征图作为下一层的输入，因此下一层每个卷积核通道也会分组，然后组内所有卷积核通道直接相加成一个通道即可

![image-20220122160426504](C:\Users\dyh20200207\AppData\Roaming\Typora\typora-user-images\image-20220122160426504.png)

在更新公式中，上面的式子是简单的SGD，下面的式子第一项计算该卷积核所在组的平均梯度，第二项为普通的权重衰减，第三项会强制卷积核朝组内中心方向更新

![image-20220122160558730](C:\Users\dyh20200207\AppData\Roaming\Typora\typora-user-images\image-20220122160558730.png)

第三项就是对于上面式子的求导，其中X用来描述组内卷积核互相的相似程度，求导后更新权重，可使得组内卷积核的相似度不断增加。
